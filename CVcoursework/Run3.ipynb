{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a34d435e",
   "metadata": {
    "id": "a34d435e"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from yellowbrick.cluster.elbow import kelbow_visualizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f19d5a-4eef-4fa3-84ee-06d533ccfc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from sklearn.metrics import make_scorer, precision_score\n",
    "\n",
    "# Decorator turns into scorer object to be used with \n",
    "# grid search.\n",
    "@make_scorer\n",
    "def avg_precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Average precision metric.\n",
    "    Computes precision for each class independently\n",
    "    then take average.\n",
    "    Args:\n",
    "        y_true (numpy.array): array of true y values. \n",
    "        y_pred(numpy.array): array of predicted y values.\n",
    "    Returns:\n",
    "        (float) average precision.\n",
    "    \n",
    "    \"\"\"\n",
    "    precision=[]\n",
    "    for idx, label in enumerate(np.unique(y_true)):\n",
    "        precision.append(precision_score(y_true == label, y_pred == label))\n",
    "    return np.mean(precision)\n",
    "\n",
    "\n",
    "def create_dataset(dir, transform=None, labeled=True):\n",
    "    \"\"\"\n",
    "    Read in data and apply transformation.\n",
    "    Args:\n",
    "        dir (string): path to data folder\n",
    "        transform (torchvision.Transform): transform to apply to data.\n",
    "        labeled (bool): if data is not contained within subfolders indicating\n",
    "            labels then create dummy folder and move data.\n",
    "    Returns:\n",
    "        (torch.Dataset) transformed data.\n",
    "    \"\"\"\n",
    "    if not labeled:\n",
    "        # get file names in folder\n",
    "        file_names = os.listdir(dir)\n",
    "        # create sub folder and move images\n",
    "        target_dir = dir + '/dummy_class/'\n",
    "        os.makedirs(target_dir)\n",
    "        for file_name in file_names:\n",
    "            shutil.move(os.path.join(dir, file_name), target_dir)\n",
    "\n",
    "    dataset = datasets.ImageFolder(dir, transform)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88e8de0-792b-4978-8bfc-f18c9f70639d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-0143e700ef55>, line 54)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-0143e700ef55>\"\u001b[1;36m, line \u001b[1;32m54\u001b[0m\n\u001b[1;33m    ZeroMeanTransform(),\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torch import flatten\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "##-------------------------------------- FEATURE EXTRACTION CLASSES -----------------------## \n",
    "class ZeroMeanTransform:\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Convert image to numpy array, \n",
    "        do any preprocessing you like then \n",
    "        convert back to the PIL Image.\n",
    "        Args:\n",
    "            img(PIL.Image): input image \n",
    "        Returns:\n",
    "            (PIL.Image) processed image\n",
    "        \"\"\"\n",
    "        x = np.array(img, dtype=np.float32)\n",
    "        mean = np.mean(img)\n",
    "        return Image.fromarray((x - mean))\n",
    "\n",
    "class UnitLenTransform:\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Convert image to numpy array, \n",
    "        do any preprocessing you like then \n",
    "        convert back to the PIL Image.\n",
    "        Args:\n",
    "            img (PIL.Image): input image \n",
    "        Returns:\n",
    "            (PIL.Image) processed image\n",
    "        \"\"\"\n",
    "        x = np.array(img)\n",
    "        cv2.normalize(x, x, alpha=1, dtype=cv2.CV_32F)\n",
    "        return Image.fromarray(x)\n",
    "\n",
    "##------------------------------------------------------------------------------------------##\n",
    "\n",
    "##-------------------------------------- TRANSFORM FUNCTIONS -------------------------------##\n",
    "def run3_transforms(resize=200):\n",
    "    \"\"\"\n",
    "    Compute tiny image feature.\n",
    "    Args:\n",
    "        resize (int): the dimensions of the tiny image.\n",
    "        crop (int): the dimensions of the center cropped array.\n",
    "    Returns:\n",
    "        (numpy.array): Tiny image flattened numpy array. \n",
    "            Dimensions are (num input samples, resize x resize) \n",
    "    \"\"\"\n",
    "    return transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                               transforms.Resize(resize)\n",
    "                               ZeroMeanTransform(),\n",
    "                               UnitLenTransform(),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Lambda(lambda x: x.view(-1))])\n",
    "\n",
    "##-------------------------------------------------------------------------------------------##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8026a9d",
   "metadata": {
    "id": "a8026a9d"
   },
   "outputs": [],
   "source": [
    "def imglist(path):\n",
    "    return [os.path.join(path, f) for f in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c3ad889",
   "metadata": {
    "id": "1c3ad889"
   },
   "outputs": [],
   "source": [
    "def descriptorFormation(descriptor_list):\n",
    "    descriptors = descriptor_list[0][1]\n",
    "    img_count=0\n",
    "    #Stacking\n",
    "    for image_path, descriptor in descriptor_list[1:]:\n",
    "        img_count+=1\n",
    "        #Array of all features\n",
    "        descriptors = np.vstack((descriptors, descriptor))\n",
    "        #print(\"Stacking of Descriptors of image {} complete......\".format(img_count))\n",
    "    print(\"Descriptors stacked successfully!\")\n",
    "    descriptors_float = descriptors.astype(float)\n",
    "    return(descriptors_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa83c327",
   "metadata": {
    "id": "aa83c327"
   },
   "outputs": [],
   "source": [
    "def getDescriptors(image_paths):\n",
    "    descriptor_list = []\n",
    "    img_count=0\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        im = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        m, n = im.shape\n",
    "        sift = cv2.SIFT_create()\n",
    "        step_size = 5\n",
    "        kp = [cv2.KeyPoint(x, y, size=step_size, octave=2) \n",
    "                  for y in range(0, m, step_size) \n",
    "                  for x in range(0, n, step_size)]\n",
    "        _, dense_feat = sift.compute(im, kp)\n",
    "        descriptor_list.append((image_path, dense_feat))\n",
    "        img_count += 1\n",
    "        #print(\"Extraction done for \" + str(img_count))\n",
    "    \n",
    "    print(\"Feature extraction done!\")\n",
    "    return(descriptor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6845b514-e83c-4831-84c1-b1931c3eab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'images/training'\n",
    "training_names = os.listdir(train_path)\n",
    "image_paths = []\n",
    "#Class label for all images\n",
    "image_classes = []\n",
    "class_id = 0\n",
    "labelMap = {}\n",
    "\n",
    "for training_name in training_names:\n",
    "    labelMap[class_id] = training_name\n",
    "    dir = os.path.join(train_path, training_name)\n",
    "    class_path = imglist(dir)\n",
    "    image_paths+=class_path\n",
    "    image_classes+=[class_id]*len(class_path)\n",
    "    class_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9769281",
   "metadata": {
    "id": "c9769281"
   },
   "outputs": [],
   "source": [
    "def quantisation(image_paths, descriptor_list, k, codebook, scaler):\n",
    "    im_features = np.zeros((len(image_paths), k), \"float32\")\n",
    "    for i in range(len(image_paths)):\n",
    "        descriptors = scaler.transform(descriptor_list[i][1])\n",
    "        codes, distances = vq(descriptors, codebook)\n",
    "        for code in codes:\n",
    "            im_features[i][code] += 1\n",
    "    return(im_features)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e31ebb7-b136-458c-8f6e-d9f3b9320fc2",
   "metadata": {},
   "source": [
    "## Feature Extraction and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f973902",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f973902",
    "outputId": "0f05245e-d84a-464b-f8e7-acb2d4a06dda"
   },
   "outputs": [],
   "source": [
    "train_path = 'images/training'\n",
    "training_names = os.listdir(train_path)\n",
    "image_paths = []\n",
    "#Class label for all images\n",
    "image_classes = []\n",
    "class_id = 0\n",
    "labelMap = {}\n",
    "\n",
    "for training_name in training_names:\n",
    "    labelMap[class_id] = training_name\n",
    "    dir = os.path.join(train_path, training_name)\n",
    "    class_path = imglist(dir)\n",
    "    image_paths+=class_path\n",
    "    image_classes+=[class_id]*len(class_path)\n",
    "    class_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cf98638-1821-4b69-a905-b5b4aea6da90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction done!\n"
     ]
    }
   ],
   "source": [
    "descriptor_list = getDescriptors(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b164cc03-0978-4a10-8f7a-7fbfdbc97e43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b164cc03-0978-4a10-8f7a-7fbfdbc97e43",
    "outputId": "1cc26d81-122a-4428-809a-9b5ac82fedd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptors stacked successfully!\n"
     ]
    }
   ],
   "source": [
    "descriptors_float = descriptorFormation(descriptor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b60cc2f-a4b5-4d21-a697-ae94108fd893",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b60cc2f-a4b5-4d21-a697-ae94108fd893",
    "outputId": "e3773a68-4516-4af1-d793-61a5007df140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4060424\n"
     ]
    }
   ],
   "source": [
    "print(len(descriptors_float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tw5UQLm0C2yW",
   "metadata": {
    "id": "tw5UQLm0C2yW"
   },
   "outputs": [],
   "source": [
    "#Normalising patches\n",
    "scaler = StandardScaler()\n",
    "normalised_descriptors = scaler.fit_transform(descriptors_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8afAozfTEEcM",
   "metadata": {
    "id": "8afAozfTEEcM"
   },
   "outputs": [],
   "source": [
    "#Sample descriptors\n",
    "sampled_descriptors = normalised_descriptors[np.random.choice(normalised_descriptors.shape[0], 500000, replace=False), :]\n",
    "\n",
    "sampled_descriptors_for_gs = normalised_descriptors[np.random.choice(normalised_descriptors.shape[0], 10000, replace=False), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb71e9c3-95c9-49e3-8f75-5ac6c3a7f8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(sampled_descriptors_for_gs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bb63241-c94d-4f46-8710-62d10db0b679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weighted_ssd = {}\n",
    "\n",
    "for k in range(100, 1000, 100):\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(sampled_descriptors_for_gs)\n",
    "    weighted_ssd[k] = kmeans.inertia_/sampled_descriptors_for_gs.shape[0]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(weighted_ssd.keys()), list(weighted_ssd.values()))\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Avg weighted SSD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acf6a7ef",
   "metadata": {
    "id": "acf6a7ef"
   },
   "outputs": [],
   "source": [
    "# Create codebook\n",
    "k = 500\n",
    "voc, variance = kmeans(sampled_descriptors, k, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8f2f192",
   "metadata": {
    "id": "f8f2f192",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quantisation of features to compute histogram of visual words\n",
    "im_features = quantisation(image_paths,descriptor_list, k, voc, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f55f7da",
   "metadata": {
    "id": "8f55f7da"
   },
   "source": [
    "## One-vs-Rest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e13ff609-7105-4398-8d37-c9310333f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features for classifier\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "im_features_minmax = min_max_scaler.fit_transform(im_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1eada0ef",
   "metadata": {
    "id": "1eada0ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='ovr', max_iter=100)\n",
    "model.fit(im_features_minmax, image_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64d00fb3-eef7-4609-be97-c00907f3cbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.942\n"
     ]
    }
   ],
   "source": [
    "# Training data performance\n",
    "score = model.score(im_features_minmax, image_classes)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3284c4",
   "metadata": {
    "id": "6d3284c4"
   },
   "source": [
    "## Test Data Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24dd6011",
   "metadata": {
    "id": "24dd6011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction done!\n"
     ]
    }
   ],
   "source": [
    "test_path = 'images/testing'\n",
    "testing_names = os.listdir(test_path)\n",
    "\n",
    "test_image_paths = []\n",
    "test_image_classes = []\n",
    "test_image_names = []\n",
    "test_class_id = 0\n",
    "\n",
    "for testing_name in testing_names:\n",
    "    test_dir = os.path.join(test_path, testing_name)\n",
    "    test_image_paths.append(test_dir)\n",
    "    test_image_names.append(testing_name)\n",
    "        \n",
    "test_descriptor_list = getDescriptors(test_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3bd3a67",
   "metadata": {
    "id": "a3bd3a67"
   },
   "outputs": [],
   "source": [
    "# Histogram of words and feature scaling\n",
    "test_im_features = quantisation(test_image_paths, test_descriptor_list, k, voc, scaler)\n",
    "test_im_features_minmax = min_max_scaler.transform(test_im_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c23684e0-0801-43e3-b1bd-9984c3d0c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = model.predict(test_im_features_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac1c4b53-a5ba-4575-86f1-3bb6bb23f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write output to file\n",
    "\n",
    "with open('run3.txt', 'w') as f:\n",
    "    for idx in range(len(test_image_names)):\n",
    "        line = str(test_image_names[idx]) + \" \" + str(labelMap[pred_labels[idx]])\n",
    "        f.write(line)\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22852b6-489c-4930-a4e9-051b168a76fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Run2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
