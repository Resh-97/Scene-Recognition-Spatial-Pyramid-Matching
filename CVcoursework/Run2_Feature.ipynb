{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a34d435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8026a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imglist(path):\n",
    "    return [os.path.join(path, f) for f in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7317848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllRectangles(im_x,im_y,step,window):\n",
    "    \n",
    "    #Initialise Patch Size \n",
    "    minx = 0\n",
    "    maxx = im_x\n",
    "    miny = 0\n",
    "    maxy =im_y\n",
    "    step_x = step\n",
    "    step_y = step\n",
    "    window_width = window\n",
    "    window_height = window\n",
    "    rectangle = [] \n",
    "    x = minx;\n",
    "    y = miny;\n",
    "    hasNext = True\n",
    "\n",
    "    while hasNext:\n",
    "        nextX = x + step_x;\n",
    "        nextY = y;\n",
    "        if (nextX + window_width > maxx):\n",
    "            nextX = minx;\n",
    "            nextY += step_y;\n",
    "        rec_dim = [x, y, window_width, window_height]\n",
    "        #print(rec_patch)\n",
    "        rectangle.append(rec_dim);\n",
    "        x = nextX;\n",
    "        y = nextY;\n",
    "\n",
    "        if (y + window_height > maxy):\n",
    "            hasNext = False\n",
    "    #print(\"All rectangular patches retrieved.......\")\n",
    "    return rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44e4b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtraction(im, rectangle):\n",
    "    feature = []\n",
    "    for x,y,w,h in rectangle:\n",
    "        patch_img = im[x:x+w,y:y+w]\n",
    "        img_array = np.array(patch_img)\n",
    "        flat_arr = img_array.ravel()\n",
    "        vector = flat_arr.tolist()\n",
    "        feature.append(vector)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c3ad889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptorFormation(descriptor_list):\n",
    "    descriptors = descriptor_list[0][1]\n",
    "    img_count=0\n",
    "    #Stacking\n",
    "    for image_path, descriptor in descriptor_list[1:]:\n",
    "        img_count+=1\n",
    "        descriptors = np.vstack((descriptors, descriptor))\n",
    "        #print(\"Stacking of Descriptors of image {} complete......\".format(img_count))\n",
    "    print(\"Descriptors stacked successfully!\")\n",
    "    descriptors_float = descriptors.astype(float)\n",
    "    return(descriptors_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa83c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDescriptors(image_paths):\n",
    "    descriptor_list = []\n",
    "    img_count=0\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        img_count+=1\n",
    "        im = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        m, n = im.shape\n",
    "        rectangle = getAllRectangles(m,n,4,8) \n",
    "        feature = featureExtraction(im, rectangle)\n",
    "        #print(\"Image features extracted for image {}......\".format(img_count))\n",
    "        descriptor_list.append((image_path, feature))\n",
    "    print(\"Feature extraction done!\")\n",
    "    return(descriptor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9769281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantisation(image_paths,descriptor_list):\n",
    "    im_features = np.zeros((len(image_paths), k), \"float32\")\n",
    "    for i in range(len(image_paths)):\n",
    "        words, distance = vq(descriptor_list[i][1],voc)\n",
    "        for w in words:\n",
    "            im_features[i][w] += 1\n",
    "    return(im_features)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0f973902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction done!\n"
     ]
    }
   ],
   "source": [
    "train_path = 'images/training'\n",
    "training_names = os.listdir(train_path)\n",
    "image_paths = []\n",
    "#Class label for all images\n",
    "image_classes = []\n",
    "class_id = 0\n",
    "\n",
    "for training_name in training_names:\n",
    "    dir = os.path.join(train_path, training_name)\n",
    "    class_path = imglist(dir)\n",
    "    image_paths+=class_path\n",
    "    image_classes+=[class_id]*len(class_path)\n",
    "    class_id+=1\n",
    "     \n",
    "descriptor_list = getDescriptors(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94898598-0ae9-43c8-b7fa-c99e81e287e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3185\n",
      "[[34, 37, 31, 26, 28, 26, 20, 23, 41, 44, 43, 35, 32, 36, 31, 26, 42, 38, 41, 40, 33, 32, 32, 30, 49, 44, 39, 42, 41, 31, 31, 34, 45, 51, 46, 41, 45, 38, 35, 36, 37, 41, 45, 36, 33, 33, 33, 29, 49, 43, 48, 49, 42, 39, 39, 32, 51, 45, 40, 48, 46, 38, 37, 35]]\n"
     ]
    }
   ],
   "source": [
    "#print(len(descriptor_list[0][1]))\n",
    "#print(descriptor_list[0][1][-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b164cc03-0978-4a10-8f7a-7fbfdbc97e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptors stacked successfully!\n"
     ]
    }
   ],
   "source": [
    "descriptors_float = descriptorFormation(descriptor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4b60cc2f-a4b5-4d21-a697-ae94108fd893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6016463\n"
     ]
    }
   ],
   "source": [
    "#print(len(descriptors_float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "acf6a7ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 22.4 GiB for an array with shape (6016463, 500) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-4b199d28451f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescriptors_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\cluster\\vq.py\u001b[0m in \u001b[0;36mkmeans\u001b[1;34m(obs, k_or_guess, iter, thresh, check_finite)\u001b[0m\n\u001b[0;32m    453\u001b[0m         \u001b[1;31m# the initial code book is randomly selected from observations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[0mguess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_kpoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m         \u001b[0mbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_kmeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthresh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdist\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbest_dist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m             \u001b[0mbest_book\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\cluster\\vq.py\u001b[0m in \u001b[0;36m_kmeans\u001b[1;34m(obs, guess, thresh)\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mdiff\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthresh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;31m# compute membership and distances between obs and code_book\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m         \u001b[0mobs_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode_book\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m         \u001b[0mprev_avg_dists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistort\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;31m# recalc code_book as centroids of associated obs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\cluster\\vq.py\u001b[0m in \u001b[0;36mvq\u001b[1;34m(obs, code_book, check_finite)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_vq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_code_book\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpy_vq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode_book\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_vq.pyx\u001b[0m in \u001b[0;36mscipy.cluster._vq.vq\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_vq.pyx\u001b[0m in \u001b[0;36mscipy.cluster._vq._vq\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 22.4 GiB for an array with shape (6016463, 500) and data type float64"
     ]
    }
   ],
   "source": [
    "k = 500  \n",
    "voc, variance = kmeans(descriptors_float, k, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8f2f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the histogram of features and represent them as vector\n",
    "im_features = quantisation(image_paths,descriptor_list)\n",
    "\n",
    "# Scaling the words\n",
    "stdSlr = StandardScaler().fit(im_features)\n",
    "im_features = stdSlr.transform(im_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f55f7da",
   "metadata": {},
   "source": [
    "### The Next Block has to be replaced with the One for all Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eada0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(multi_class='ovr')\n",
    "model.fit(im_features, image_classes)\n",
    "\n",
    "#Test accuracy\n",
    "y_pred = model.predict(im_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3284c4",
   "metadata": {},
   "source": [
    "### To Validate using Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd6011",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'images/testing'\n",
    "testing_names = os.listdir(test_path)\n",
    "\n",
    "test_image_paths = []\n",
    "test_image_classes = []\n",
    "test_class_id = 0\n",
    "\n",
    "for testing_name in testing_names:\n",
    "    test_dir = os.path.join(test_path, testing_name)\n",
    "    test_image_paths.append(test_dir)\n",
    "    \n",
    "test_descriptor_list = getDescriptors(test_image_paths)\n",
    "test_descriptors_float = descriptorFormation(test_descriptor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3bd3a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_im_features = quantisation(image_paths,descriptor_list)\n",
    "test_im_features = stdSlr.transform(test_im_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
