{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a34d435e",
   "metadata": {
    "id": "a34d435e"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#from sklearn.cluster import KMeans\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from yellowbrick.cluster.elbow import kelbow_visualizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b4249-e2c8-4a83-aa9b-a2b3df25cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add docstrings for all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8026a9d",
   "metadata": {
    "id": "a8026a9d"
   },
   "outputs": [],
   "source": [
    "def imglist(path):\n",
    "    return [os.path.join(path, f) for f in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7317848",
   "metadata": {
    "id": "d7317848"
   },
   "outputs": [],
   "source": [
    "def getAllRectangles(im_x,im_y,step,window): \n",
    "    #Initialise Patch Size \n",
    "    minx = 0\n",
    "    maxx = im_x\n",
    "    miny = 0\n",
    "    maxy =im_y\n",
    "    step_x = step\n",
    "    step_y = step\n",
    "    window_width = window\n",
    "    window_height = window\n",
    "    rectangle = [] \n",
    "    x = minx;\n",
    "    y = miny;\n",
    "    hasNext = True\n",
    "\n",
    "    while hasNext:\n",
    "        nextX = x + step_x;\n",
    "        nextY = y;\n",
    "        if (nextX + window_width > maxx):\n",
    "            nextX = minx;\n",
    "            nextY += step_y;\n",
    "        rec_dim = [x, y, window_width, window_height]\n",
    "        #print(rec_patch)\n",
    "        rectangle.append(rec_dim);\n",
    "        x = nextX;\n",
    "        y = nextY;\n",
    "\n",
    "        if (y + window_height > maxy):\n",
    "            hasNext = False\n",
    "    #print(\"All rectangular patches retrieved.......\")\n",
    "    return rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e4b2b6",
   "metadata": {
    "id": "44e4b2b6"
   },
   "outputs": [],
   "source": [
    "def featureExtraction(im, rectangle):\n",
    "    feature = []\n",
    "    for x,y,w,h in rectangle:\n",
    "        patch_img = im[x:x+w,y:y+w]\n",
    "        img_array = np.array(patch_img)\n",
    "        flat_arr = img_array.ravel()\n",
    "        vector = flat_arr.tolist()\n",
    "        feature.append(vector)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c3ad889",
   "metadata": {
    "id": "1c3ad889"
   },
   "outputs": [],
   "source": [
    "def descriptorFormation(descriptor_list):\n",
    "    descriptors = descriptor_list[0][1]\n",
    "    img_count=0\n",
    "    #Stacking\n",
    "    for image_path, descriptor in descriptor_list[1:]:\n",
    "        img_count+=1\n",
    "        #Array of all features\n",
    "        descriptors = np.vstack((descriptors, descriptor))\n",
    "        #print(\"Stacking of Descriptors of image {} complete......\".format(img_count))\n",
    "    print(\"Descriptors stacked successfully!\")\n",
    "    descriptors_float = descriptors.astype(float)\n",
    "    return(descriptors_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa83c327",
   "metadata": {
    "id": "aa83c327"
   },
   "outputs": [],
   "source": [
    "def getDescriptors(image_paths):\n",
    "    descriptor_list = []\n",
    "    img_count=0\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        img_count+=1\n",
    "        im = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        m, n = im.shape\n",
    "        rectangle = getAllRectangles(m,n,4,8) \n",
    "        feature = featureExtraction(im, rectangle)\n",
    "        #print(\"Image features extracted for image {}......\".format(img_count))\n",
    "        descriptor_list.append((image_path, feature))\n",
    "    print(\"Feature extraction done!\")\n",
    "    return(descriptor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9769281",
   "metadata": {
    "id": "c9769281"
   },
   "outputs": [],
   "source": [
    "def quantisation(image_paths, descriptor_list, k, codebook, scaler):\n",
    "    im_features = np.zeros((len(image_paths), k), \"float32\")\n",
    "    for i in range(len(image_paths)):\n",
    "        descriptors = scaler.transform(descriptor_list[i][1])\n",
    "        codes, distances = vq(descriptors, codebook)\n",
    "        for code in codes:\n",
    "            im_features[i][code] += 1\n",
    "    return(im_features)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e31ebb7-b136-458c-8f6e-d9f3b9320fc2",
   "metadata": {},
   "source": [
    "## Feature Extraction and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f973902",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f973902",
    "outputId": "0f05245e-d84a-464b-f8e7-acb2d4a06dda"
   },
   "outputs": [],
   "source": [
    "train_path = 'images/training'\n",
    "training_names = os.listdir(train_path)\n",
    "image_paths = []\n",
    "#Class label for all images\n",
    "image_classes = []\n",
    "class_id = 0\n",
    "labelMap = {}\n",
    "\n",
    "for training_name in training_names:\n",
    "    labelMap[class_id] = training_name\n",
    "    dir = os.path.join(train_path, training_name)\n",
    "    class_path = imglist(dir)\n",
    "    image_paths+=class_path\n",
    "    image_classes+=[class_id]*len(class_path)\n",
    "    class_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623365e6-1b05-4af5-b961-960091eac0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor_list = getDescriptors(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b164cc03-0978-4a10-8f7a-7fbfdbc97e43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b164cc03-0978-4a10-8f7a-7fbfdbc97e43",
    "outputId": "1cc26d81-122a-4428-809a-9b5ac82fedd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptors stacked successfully!\n"
     ]
    }
   ],
   "source": [
    "descriptors_float = descriptorFormation(descriptor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b60cc2f-a4b5-4d21-a697-ae94108fd893",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b60cc2f-a4b5-4d21-a697-ae94108fd893",
    "outputId": "e3773a68-4516-4af1-d793-61a5007df140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6016463\n"
     ]
    }
   ],
   "source": [
    "print(len(descriptors_float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tw5UQLm0C2yW",
   "metadata": {
    "id": "tw5UQLm0C2yW"
   },
   "outputs": [],
   "source": [
    "#Normalising patches\n",
    "scaler = StandardScaler()\n",
    "normalised_descriptors = scaler.fit_transform(descriptors_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8afAozfTEEcM",
   "metadata": {
    "id": "8afAozfTEEcM"
   },
   "outputs": [],
   "source": [
    "#Sample descriptors\n",
    "sampled_descriptors = normalised_descriptors[np.random.choice(normalised_descriptors.shape[0], 500000, replace=False), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9617a64c-67e5-4dda-a85e-4bd5e0e41a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal #clusters estimation using elbow technique\n",
    "# kelbow_visualizer(KMeans(), sampled_descriptors, k=(400,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acf6a7ef",
   "metadata": {
    "id": "acf6a7ef"
   },
   "outputs": [],
   "source": [
    "k = 500\n",
    "voc, variance = kmeans(sampled_descriptors, k, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8f2f192",
   "metadata": {
    "id": "f8f2f192"
   },
   "outputs": [],
   "source": [
    "# Quantisation of features to compute histogram of visual words\n",
    "im_features = quantisation(image_paths,descriptor_list, k, voc, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f55f7da",
   "metadata": {
    "id": "8f55f7da"
   },
   "source": [
    "## One-vs-Rest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e13ff609-7105-4398-8d37-c9310333f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features for classifier\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "im_features_minmax = min_max_scaler.fit_transform(im_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1eada0ef",
   "metadata": {
    "id": "1eada0ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='ovr', max_iter=100)\n",
    "model.fit(im_features_minmax, image_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64d00fb3-eef7-4609-be97-c00907f3cbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8893333333333333\n"
     ]
    }
   ],
   "source": [
    "# Training data performance\n",
    "score = model.score(im_features_minmax, image_classes)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3284c4",
   "metadata": {
    "id": "6d3284c4"
   },
   "source": [
    "## Test Data Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24dd6011",
   "metadata": {
    "id": "24dd6011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction done!\n"
     ]
    }
   ],
   "source": [
    "test_path = 'images/testing'\n",
    "testing_names = os.listdir(test_path)\n",
    "\n",
    "test_image_paths = []\n",
    "test_image_classes = []\n",
    "test_image_names = []\n",
    "test_class_id = 0\n",
    "\n",
    "for testing_name in testing_names:\n",
    "    test_dir = os.path.join(test_path, testing_name)\n",
    "    test_image_paths.append(test_dir)\n",
    "    test_image_names.append(testing_name)\n",
    "    \n",
    "test_descriptor_list = getDescriptors(test_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3bd3a67",
   "metadata": {
    "id": "a3bd3a67"
   },
   "outputs": [],
   "source": [
    "# Histogram of words and feature scaling\n",
    "test_im_features = quantisation(test_image_paths, test_descriptor_list, k, voc, scaler)\n",
    "test_im_features_minmax = min_max_scaler.transform(test_im_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c23684e0-0801-43e3-b1bd-9984c3d0c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = model.predict(test_im_features_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac1c4b53-a5ba-4575-86f1-3bb6bb23f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write output to file\n",
    "\n",
    "with open('run3.txt', 'w') as f:\n",
    "    for idx in range(len(test_image_names)):\n",
    "        line = str(test_image_names[idx]) + \" \" + str(labelMap[pred_labels[idx]])\n",
    "        f.write(line)\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e749b2e-fb60-400a-8323-bb1dc7be4870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Run2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
